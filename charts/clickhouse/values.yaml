---
global:
  image:
    # -- Overrides the Docker registry globally for all images
    registry: null
  # -- Overrides the storage class for all PVC with persistence enabled.
  storageClass: &GLOBAL_SC null
  # -- Kubernetes cluster domain
  # It is used only when components are installed in different namespace
  clusterDomain: cluster.local

# -- Cloud service being deployed on (example: `aws`, `azure`, `gcp`, `hcloud`, `other`).
# Based on the cloud, storage class for the persistent volume is selected.
# When set to 'aws' or 'gcp', new expandible storage class is created.
# When set to something else or not set, the default storage class (if any) from the k8s cluster is selected.
cloud: other

###
###
### ---- ZOOKEEPER ----
###
###

# Zookeeper default values
zookeeper:
  #
  # Please DO NOT override this value.
  # This chart installs Zookeeper separately.
  # Only if you know what you are doing, proceed with overriding.
  #

  # -- Whether to install zookeeper. If false, `clickhouse.externalZookeeper` must be set.
  enabled: true

  # -- Name override for zookeeper app
  nameOverride: ""
  # -- Fullname override for zookeeper app
  fullnameOverride: ""

  # -- Whether to install zookeeper into a different namespace than the parent
  namespaceOverride: ""

  # -- Zookeeper pod(s) annotation.
  podAnnotations: {}

  autopurge:
    # -- The time interval (in hours) for which the purge task has to be triggered
    purgeInterval: 1

  metrics:
    # -- Enable Prometheus to access ZooKeeper metrics endpoint.
    enabled: false

    service:
      # -- ZooKeeper metrics service annotation
      annotations: {}

  # -- Minimal SERVER_ID value, nodes increment their IDs respectively.
  # Servers increment their ID starting at this minimal value.
  # Eg. with `minServerId=10` and 3 replicas, server IDs will be 10,
  # 11, 12 for z-0, z-1 and z-2 respectively.
  minServerId: 1

  # -- Replica count for zookeeper
  replicaCount: 1

  # Enable persistence using Persistent Volume Claims
  #
  # Ref: https://kubernetes.io/docs/user-guide/persistent-volumes/
  persistence:
    # -- Enable ZooKeeper data persistence using PVC. If false, use emptyDir
    enabled: true

    # -- Name of an existing PVC to use (only when deploying a single replica)
    existingClaim: ""

    # -- PVC Storage Class for ZooKeeper data volume
    # If defined, storageClassName: <storageClass>
    # If set to "-", storageClassName: "", which disables dynamic provisioning
    # If undefined (the default) or set to null, no storageClassName spec is
    #   set, choosing the default provisioner.  (gp2 on AWS, standard on
    #   GKE, AWS & OpenStack)
    #
    storageClass: *GLOBAL_SC

    # -- PVC Access modes
    accessModes:
      - ReadWriteOnce

    # -- PVC Storage Request for ZooKeeper data volume
    size: 8Gi

    # -- Annotations for the PVC
    annotations: {}

###
###
### ---- CLICKHOUSE ----
###
###

# -- Name of the clickhouse component
name: clickhouse

# -- Whether to install clickhouse. If false, `clickhouse.host` must be set
enabled: true

# -- Which namespace to install clickhouse and `clickhouse-operator` to (defaults to namespace chart is installed to)
namespace: ""
# -- Name override for clickhouse
nameOverride: ""
# -- Fullname override for clickhouse
fullnameOverride: ""

# -- Clickhouse cluster
cluster: cluster
# -- Clickhouse database
database: signoz_metrics
# -- Clickhouse user
user: admin
# -- Clickhouse password
password: 27ff0399-0d3a-4bd8-919d-17c2181e6fb9

# -- Clickhouse cluster replicas
replicasCount: 1
# -- Clickhouse cluster shards
shardsCount: 1

# -- Clickhouse image
image:
  # -- Clickhouse image registry to use.
  registry: docker.io
  # -- Clickhouse image repository to use.
  repository: clickhouse/clickhouse-server
  # -- Clickhouse image tag.
  # Note: SigNoz does not support all versions of ClickHouse.
  # Please override the default only if you know what you are doing.
  tag: 22.8.8-alpine
  # -- Clickhouse image pull policy.
  pullPolicy: IfNotPresent

# Clickhouse service
service:
  # -- Annotations to use by service associated to Clickhouse instance
  annotations: {}
  # -- Service Type: LoadBalancer (allows external access) or NodePort (more secure, no extra cost)
  type: ClusterIP
  # -- Clickhouse HTTP port
  httpPort: 8123
  # -- Clickhouse TCP port
  tcpPort: 9000

# -- Whether to use TLS connection connecting to ClickHouse
secure: false
# -- Whether to verify TLS certificate on connection to ClickHouse
verify: false
# -- URL for external zookeeper.
externalZookeeper: {}
  # servers:
  #   - host: signoz-zookeeper
  #     port: 2181

# -- Node selector for settings for clickhouse pod
nodeSelector: {}
# -- Toleration labels for clickhouse pod assignment
tolerations: []
# -- Affinity settings for clickhouse pod
affinity: {}

# -- Configure resource requests and limits. Update according to your own use
# case as these values might not be suitable for your workload.
# Ref: http://kubernetes.io/docs/user-guide/compute-resources/
#
# @default -- See `values.yaml` for defaults
resources:
  requests:
    cpu: 100m
    memory: 200Mi
#   limits:
#     cpu: 2000m
#     memory: 4Gi

# -- Security context for Clickhouse node
securityContext:
  enabled: true
  runAsUser: 101
  runAsGroup: 101
  fsGroup: 101

# -- An allowlist of IP addresses or network masks the ClickHouse user is
# allowed to access from. By default anything within a private network will be
# allowed. This should suffice for most use case although to expose to other
# networks you will need to update this setting.
#
# Refs:
# - https://clickhouse.com/docs/en/operations/settings/settings-users/#user-namenetworks
# - https://en.wikipedia.org/wiki/Reserved_IP_addresses#IPv4
allowedNetworkIps:
  - "10.0.0.0/8"
  - "100.64.0.0/10"
  - "172.16.0.0/12"
  - "192.0.0.0/24"
  - "198.18.0.0/15"
  - "192.168.0.0/16"

persistence:
  # -- Enable data persistence using PVC.
  enabled: true

  # -- Use a manually managed Persistent Volume and Claim.
  # If defined, PVC must be created manually before volume will be bound.
  #
  existingClaim: ""

  # -- Persistent Volume Storage Class to use.
  # If defined, `storageClassName: <storageClass>`.
  # If set to "-", `storageClassName: ""`, which disables dynamic provisioning
  # If undefined (the default) or set to `null`, no storageClassName spec is
  # set, choosing the default provisioner.
  #
  storageClass: null

  # -- Access Modes for persistent volume
  accessModes:
    - ReadWriteOnce

  # -- Persistent Volume size
  size: 20Gi

# -- Clickhouse user profile configuration.
# You can use this to override profile settings, for example `default/max_memory_usage: 40000000000`
# For the full list of settings, see:
# - https://clickhouse.com/docs/en/operations/settings/settings-profiles/
# - https://clickhouse.com/docs/en/operations/settings/settings/
#
profiles: {}

# -- Default user profile configuration for Clickhouse. !!! Please DO NOT override this !!!
defaultProfiles:
  default/allow_experimental_window_functions: "1"
  default/allow_nondeterministic_mutations: "1"


# -- Clickhouse cluster layout. (Experimental, use at own risk)
# For a full list of options, see
# https://github.com/Altinity/clickhouse-operator/blob/master/docs/custom_resource_explained.md
# section on clusters and layouts.
layout:
  shardsCount: 1
  replicasCount: 1

# -- ClickHouse settings configuration.
# You can use this to override settings, for example `prometheus/port: 9363`
# For the full list of settings, see:
# - https://clickhouse.com/docs/en/operations/settings/settings/
settings: {}
  # Uncomment those lines if you want to enable the built-in Prometheus HTTP endpoint in ClickHouse.
  # prometheus/endpoint: /metrics
  # prometheus/port: 9363
  # prometheus/metrics: true
  # prometheus/events: true
  # prometheus/asynchronous_metrics: true

# -- Default settings configuration for ClickHouse. !!! Please DO NOT override this !!!
defaultSettings:
  format_schema_path: /etc/clickhouse-server/config.d/

# -- ClickHouse pod(s) annotation.
podAnnotations: {}
  # Uncomment lines below to enable scraping of ClickHouse metrics.
  # Be sure to uncomment `setting` to enable built-in Prometheus HTTP endpoint.
  # signoz.io/scrape: 'true'
  # signoz.io/port: '9363'
  # signoz.io/path: /metrics

# -- Topologies on how to distribute the ClickHouse pod.
# Possible values can be found here:
# https://github.com/Altinity/clickhouse-operator/blob/1414503921da3ae475eb6f9a296d3475a6993768/docs/chi-examples/99-clickhouseinstallation-max.yaml#L428-L481
podDistribution:
  - scope: ClickHouseInstallation
    type: ShardAntiAffinity
    topologyKey: kubernetes.io/hostname

# Cold storage configuration
coldStorage:
  # -- Whether to enable S3 cold storage
  enabled: false
  # -- Reserve free space on default disk (in bytes)
  defaultKeepFreeSpaceBytes: "10485760"
  # -- AWS S3 endpoint
  endpoint: https://<bucket-name>.s3.amazonaws.com/data/
  # AWS role configuration - to use environment variables instead of passing access and secret keys
  role:
    # -- Whether to enable AWS IAM ARN role.
    enabled: false
    # -- Annotations to use by service account associated to Clickhouse instance
    annotations:
      # aws role arn
      eks.amazonaws.com/role-arn: arn:aws:iam::******:role/*****
  # -- AWS Access Key
  accessKey: <access_key_id>
  # -- AWS Secret Access Key
  secretAccess: <secret_access_key>


###
###
### ---- MISC ----
###
###

# -- When the `installCustomStorageClass` is enabled with `cloud` set as `gcp` or `aws`,
# it creates custom storage class with volume expansion permission.
#
installCustomStorageClass: false


###
###
### ---- CLICKHOUSE OPERATOR ----
###
###
clickhouseOperator:
  # -- name of the component
  name: operator

  # -- Version of the operator
  version: 0.19.1

  # -- Clickhouse Operator image
  image:
    # -- Clickhouse Operator image registry to use.
    registry: docker.io
    # -- Clickhouse Operator image repository to use.
    repository: altinity/clickhouse-operator
    # -- Clickhouse Operator image tag.
    tag: 0.19.1
    # -- Clickhouse Operator image pull policy.
    pullPolicy: IfNotPresent

  serviceAccount:
    # -- Specifies whether a service account should be created
    create: true
    # -- Annotations to add to the service account
    annotations: {}
    # -- The name of the service account to use.
    # If not set and create is true, a name is generated using the fullname template
    name:

  # -- Clickhouse Operator pod(s) annotation.
  podAnnotations:
    signoz.io/port: '8888'
    signoz.io/scrape: 'true'

  # -- Clickhouse Operator node selector
  nodeSelector: {}

  # -- Clickhouse logging config
  logger:
    # -- Logging level. Acceptable values: trace, debug, information, warning, error.
    level: information
    # -- Size of the file. Applies to log and errorlog. Once the file reaches size,
    # ClickHouse archives and renames it, and creates a new log file in its place.
    size: 1000M
    # -- The number of archived log files that ClickHouse stores.
    count: 10
    # -- Whether to send log and errorlog to the console instead of file. To enable, set to 1 or true.
    console: true

  # -- Metrics Exporter config.
  metricsExporter:
    # -- name of the component
    name: metrics-exporter

    # -- Metrics Exporter service
    service:
      # -- Annotations to use by service associated to Metrics Exporter
      annotations: {}
      # -- Service Type: LoadBalancer (allows external access) or NodePort (more secure, no extra cost)
      type: ClusterIP
      # -- Metrics Exporter port
      port: 8888

    # -- Metrics Exporter image
    image:
      # -- Metrics Exporter image registry to use.
      registry: docker.io
      # -- Metrics Exporter image repository to use.
      repository: altinity/metrics-exporter
      # -- Metrics Exporter image tag.
      tag: 0.19.1
      # -- Metrics Exporter image pull policy.
      pullPolicy: IfNotPresent
