# Global override values
global:
  # -- Overrides the Docker registry globally for all images
  imageRegistry: null
  # -- Global Image Pull Secrets
  imagePullSecrets: []
  # -- Overrides the storage class for all PVC with persistence enabled.
  storageClass: null
  # -- Kubernetes cluster domain
  # It is used only when components are installed in different namespace
  clusterDomain: cluster.local
  # -- Kubernetes cluster name
  # It is used to attached to telemetry data via resource detection processor
  clusterName: ""
  # -- Kubernetes cluster cloud provider along with distribution if any.
  # example: `aws`, `azure`, `gcp`, `gcp/autogke`, `hcloud`, `other`
  cloud: other

# -- K8s infra chart name override
nameOverride: ""

# -- K8s infra chart full name override
fullnameOverride: ""

# -- Whether to enable K8s infra chart
enabled: true

# -- Name of the K8s cluster. Used by OtelCollectors to attach in telemetry data.
clusterName: ""

# -- Endpoint/IP Address of the SigNoz or any other OpenTelemetry backend.
# Set it to `ingest.signoz.io:4317` for SigNoz SaaS.
#
# If set to null and the chart is installed as dependency, it will attempt
# to autogenerate the endpoint of SigNoz OtelCollector.
otelCollectorEndpoint: null

# -- Whether the OTLP endpoint is insecure.
# Set this to false, in case of secure OTLP endpoint.
otelInsecure: true

# -- Whether to skip verifying the certificate.
insecureSkipVerify: false

# -- API key of SigNoz SaaS
signozApiKey: ""

# OTLP receivers TLS
otelTlsSecrets:
  # -- Whether to enable OpenTelemetry OTLP secrets
  enabled: false

  # -- Path for the secrets volume
  path: /secrets

  # -- Name of the existing secret with TLS certificate, key and CA to be used.
  # Files in the secret must be named `cert.pem`, `key.pem` and `ca.pem`.
  existingSecretName:

  # -- TLS certificate to be included in the secret
  certificate: |
    <INCLUDE_CERTIFICATE_HERE>

  # -- TLS private key to be included in the secret
  key: |
    <INCLUDE_PRIVATE_KEY_HERE>

  # -- TLS certificate authority (CA) certificate to be included in the secret
  ca: ""

# -- Which namespace to install k8s-infra components.
# By default installed to the namespace same as the chart.
namespace: ""

# -- Presets to easily set up OtelCollector configurations.
presets:
  loggingExporter:
    enabled: false
    # Verbosity of the logging export: basic, normal, detailed
    verbosity: basic
    # Number of messages initially logged each second
    samplingInitial: 2
    # Sampling rate after the initial messages are logged
    samplingThereafter: 500
  otlpExporter:
    enabled: true
  logsCollection:
    enabled: true
    include:
      - /var/log/pods/*/*/*.log
    startAt: beginning
    includeFilePath: true
    includeFileName: false
    blacklist:
      enabled: true
      signozLogs: true
      namespaces:
        - kube-system
      pods:
        - hotrod
        - locust
      containers: []
      additionalExclude: []
    operators:
      # Find out which format is used by kubernetes
      - type: router
        id: get-format
        routes:
          - output: parser-docker
            expr: 'body matches "^\\{"'
          - output: parser-crio
            expr: 'body matches "^[^ Z]+ "'
          - output: parser-containerd
            expr: 'body matches "^[^ Z]+Z"'
      # Parse CRI-O format
      - type: regex_parser
        id: parser-crio
        regex: '^(?P<time>[^ Z]+) (?P<stream>stdout|stderr) (?P<logtag>[^ ]*) ?(?P<log>.*)$'
        output: extract_metadata_from_filepath
        timestamp:
          parse_from: attributes.time
          layout_type: gotime
          layout: '2006-01-02T15:04:05.000000000-07:00'
      # Parse CRI-Containerd format
      - type: regex_parser
        id: parser-containerd
        regex: '^(?P<time>[^ ^Z]+Z) (?P<stream>stdout|stderr) (?P<logtag>[^ ]*) ?(?P<log>.*)$'
        output: extract_metadata_from_filepath
        timestamp:
          parse_from: attributes.time
          layout: '%Y-%m-%dT%H:%M:%S.%LZ'
      # Parse Docker format
      - type: json_parser
        id: parser-docker
        output: extract_metadata_from_filepath
        timestamp:
          parse_from: attributes.time
          layout: '%Y-%m-%dT%H:%M:%S.%LZ'
      # Extract metadata from file path
      - type: regex_parser
        id: extract_metadata_from_filepath
        regex: '^.*\/(?P<namespace>[^_]+)_(?P<pod_name>[^_]+)_(?P<uid>[a-f0-9\-]+)\/(?P<container_name>[^\._]+)\/(?P<restart_count>\d+)\.log$'
        parse_from: attributes["log.file.path"]
        output: add_cluster_name
      # Add cluster name attribute from environment variable
      - id: add_cluster_name
        type: add
        field: resource["k8s.cluster.name"]
        value: EXPR(env("K8S_CLUSTER_NAME"))
        output: move_stream
      # Rename attributes
      - type: move
        id: move_stream
        from: attributes.stream
        to: attributes["log.iostream"]
        output: move_container_name
      - type: move
        id: move_container_name
        from: attributes.container_name
        to: resource["k8s.container.name"]
        output: move_namespace
      - type: move
        id: move_namespace
        from: attributes.namespace
        to: resource["k8s.namespace.name"]
        output: move_pod_name
      - type: move
        id: move_pod_name
        from: attributes.pod_name
        to: resource["k8s.pod.name"]
        output: move_restart_count
      - type: move
        id: move_restart_count
        from: attributes.restart_count
        to: resource["k8s.container.restart_count"]
        output: move_uid
      - type: move
        id: move_uid
        from: attributes.uid
        to: resource["k8s.pod.uid"]
        output: move_log
      # Clean up log body
      - type: move
        id: move_log
        from: attributes.log
        to: body
  hostMetrics:
    enabled: true
    collectionInterval: 30s
    scrapers:
      cpu: {}
      load: {}
      memory: {}
      disk: {}
      filesystem: {}
      network: {}
  kubeletMetrics:
    enabled: true
    collectionInterval: 30s
    authType: serviceAccount
    endpoint: ${K8S_NODE_NAME}:10250
    insecureSkipVerify: true
    extraMetadataLabels:
      - container.id
      - k8s.volume.type
    metricGroups:
      - container
      - pod
      - node
      - volume
  kubernetesAttributes:
    enabled: true
    # -- Whether to detect the IP address of agents and add it as an attribute to all telemetry resources.
    # If set to true, Agents will not make any k8s API calls, do any discovery of pods or extract any metadata.
    passthrough: false
    # -- Filters can be used to limit each OpenTelemetry agent to query pods based on specific
    # selector to only dramatically reducing resource requirements for very large clusters.
    filter:
      # -- Restrict each OpenTelemetry agent to query pods running on the same node
      node_from_env_var: K8S_NODE_NAME
    # -- Pod Association section allows to define rules for tagging spans, metrics,
    # and logs with Pod metadata.
    podAssociation:
      - sources:
        - from: resource_attribute
          name: k8s.pod.ip
      - sources:
        - from: resource_attribute
          name: k8s.pod.uid
      - sources:
        - from: connection
    # -- Which pod/namespace metadata to extract from a list of default metadata fields.
    extractMetadatas:
      - k8s.namespace.name
      - k8s.pod.name
      - k8s.pod.uid
      - k8s.pod.start_time
      - k8s.deployment.name
      - k8s.node.name
  clusterMetrics:
    enabled: true
    collectionInterval: 30s
    nodeConditionsToReport:
      - Ready
      - MemoryPressure
      # - DiskPressure
      # - NetworkUnavailable
      # - PIDPressure
    allocatableTypesToReport:
      - cpu
      - memory
      # - ephemeral-storage
      # - storage
  resourceDetectionInternal:
    enabled: true
    timeout: 2s
    # DO NOT CHANGE BELOW TO false, causes data duplication in case attributes mismatched.
    override: true
  resourceDetection:
    enabled: true
    timeout: 2s
    # DO NOT CHANGE BELOW TO false, causes data duplication in case attributes mismatched.
    override: true
    # detectors: include ec2/eks for AWS, gcp for GCP and azure/aks for Azure
    # env detector included below adds custom labels using OTEL_RESOURCE_ATTRIBUTES envvar
    detectors:
      # - elastic_beanstalk
      # - eks
      # - ecs
      # - ec2
      # - gcp
      # - azure
      # - heroku
      - system
    systemHostnameSources:
      - dns
      - os
      # - cname
      # - lookup

# Default values for OtelAgent
otelAgent:
  name: "otel-agent"
  image:
    registry: docker.io
    repository: otel/opentelemetry-collector-contrib
    tag: 0.79.0
    pullPolicy: IfNotPresent

  # -- Image Registry Secret Names for OtelAgent.
  # If global.imagePullSecrets is set as well, it will merged.
  imagePullSecrets: []
    # - "otelAgent-pull-secret"

  # OpenTelemetry Collector executable
  command:
    # -- OtelAgent command name
    name: /otelcol-contrib
    # -- OtelAgent command extra arguments
    extraArgs: []

  configMap:
    # -- Specifies whether a configMap should be created (true by default)
    create: true

  # OtelAgent service
  service:
    # -- Annotations to use by service associated to OtelAgent
    annotations: {}
    # -- Service Type: LoadBalancer (allows external access) or NodePort (more secure, no extra cost)
    type: ClusterIP

  serviceAccount:
    # Specifies whether a service account should be created
    create: true
    # Annotations to add to the service account
    annotations: {}
    # The name of the service account to use.
    # If not set and create is true, a name is generated using the fullname template
    name:

  # -- OtelAgent daemonset annotation.
  annotations: {}
  # -- OtelAgent pod(s) annotation.
  podAnnotations: {}
    # signoz.io/scrape: 'true'
    # signoz.io/port: '8888'
    # signoz.io/path: /metrics

  # -- Additional environments to set for OtelAgent
  additionalEnvs: {}
    # env_key: env_value

  # -- Minimum number of seconds for which a newly created Pod should be ready
  # without any of its containers crashing, for it to be considered available.
  minReadySeconds: 5

  # OtelAgent RBAC config
  clusterRole:
    # -- Specifies whether a clusterRole should be created
    create: true
    # -- Annotations to add to the clusterRole
    annotations: {}
    # -- The name of the clusterRole to use.
    # If not set and create is true, a name is generated using the fullname template
    name: ""
    # -- A set of rules as documented here.
    # ref: https://kubernetes.io/docs/reference/access-authn-authz/rbac/
    # @default -- See `values.yaml` for defaults
    rules:
      # k8sattributes processor requires these permissions
      - apiGroups: [""]
        resources: ["pods", "namespaces"]
        verbs: ["get", "list", "watch"]
      - apiGroups: ["apps"]
        resources: ["replicasets"]
        verbs: ["get", "list", "watch"]
      - apiGroups: ["extensions"]
        resources: ["replicasets"]
        verbs: ["get", "list", "watch"]
      # other processors and receivers require these permissions
      - apiGroups: [""]
        resources: ["nodes", "endpoints"]
        verbs: ["list", "watch"]
      - apiGroups: ["batch"]
        resources: ["jobs"]
        verbs: ["list", "watch"]
      - apiGroups: [""]
        resources: ["nodes/proxy"]
        verbs: ["get"]
      - apiGroups: [""]
        resources: ["nodes/stats", "configmaps", "events"]
        verbs: ["create", "get"]
      - apiGroups: [""]
        resources: ["configmaps"]
        resourceNames: ["otel-container-insight-clusterleader"]
        verbs: ["get", "update"]

    # OtelAgent clusterRoleBinding
    clusterRoleBinding:
      # Annotations to add to the clusterRoleBinding
      annotations: {}
      # The name of the clusterRoleBinding to use.
      # If not set and create is true, a name is generated using the fullname template
      name: ""

  # Configuration for ports
  ports:
    otlp:
      # -- Whether to enable service port for OTLP gRPC
      enabled: true
      # -- Container port for OTLP gRPC
      containerPort: 4317
      # -- Service port for OTLP gRPC
      servicePort: 4317
      # -- Node port for OTLP gRPC
      nodePort: ""
      # -- Host port for OTLP gRPC
      hostPort: 4317
      # -- Protocol to use for OTLP gRPC
      protocol: TCP
    otlp-http:
      # -- Whether to enable service port for OTLP HTTP
      enabled: true
      # -- Container port for OTLP HTTP
      containerPort: 4318
      # -- Service port for OTLP HTTP
      servicePort: 4318
      # -- Node port for OTLP HTTP
      nodePort: ""
      # -- Host port for OTLP HTTP
      hostPort: 4318
      # -- Protocol to use for OTLP HTTP
      protocol: TCP
    zipkin:
      # -- Whether to enable service port for Zipkin
      enabled: false
      # -- Container port for Zipkin
      containerPort: 9411
      # -- Service port for Zipkin
      servicePort: 9411
      # -- Node port for Zipkin
      nodePort: ""
      # -- Host port for Zipkin
      hostPort: 9411
      # -- Protocol to use for Zipkin
      protocol: TCP
    metrics:
      # -- Whether to enable service port for internal metrics
      enabled: true
      # -- Container port for internal metrics
      containerPort: 8888
      # -- Service port for internal metrics
      servicePort: 8888
      # -- Node port for internal metrics
      nodePort: ""
      # -- Host port for internal metrics
      hostPort: 8888
      # -- Protocol to use for internal metrics
      protocol: TCP
    zpages:
      # -- Whether to enable service port for ZPages
      enabled: false
      # -- Container port for Zpages
      containerPort: 55679
      # -- Service port for Zpages
      servicePort: 55679
      # -- Node port for Zpages
      nodePort: ""
      # -- Host port for Zpages
      hostPort: 55679
      # -- Protocol to use for Zpages
      protocol: TCP
    health-check:
      # -- Whether to enable service port for health check
      enabled: true
      # -- Container port for health check
      containerPort: 13133
      # -- Service port for health check
      servicePort: 13133
      # -- Node port for health check
      nodePort: ""
      # -- Host port for health check
      hostPort: 13133
      # -- Protocol to use for health check
      protocol: TCP
    pprof:
      # -- Whether to enable service port for pprof
      enabled: false
      # -- Container port for pprof
      containerPort: 1777
      # -- Service port for pprof
      servicePort: 1777
      # -- Node port for pprof
      nodePort: ""
      # -- Host port for pprof
      hostPort: 1777
      # -- Protocol to use for pprof
      protocol: TCP

  # -- Configure liveness probe.
  # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#define-a-liveness-command
  livenessProbe:
    enabled: true
    port: 13133
    path: /
    initialDelaySeconds: 10
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 6
    successThreshold: 1

  # -- Configure readiness probe.
  # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#define-readiness-probes
  readinessProbe:
    enabled: true
    port: 13133
    path: /
    initialDelaySeconds: 10
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 6
    successThreshold: 1

  # -- Custom liveness probe
  customLivenessProbe: {}
  # -- Custom readiness probe
  customReadinessProbe: {}

  ingress:
    # -- Enable ingress for OtelAgent
    enabled: false
    # -- Ingress Class Name to be used to identify ingress controllers
    className: ""
    # -- Annotations to OtelAgent Ingress
    annotations: {}
      # cert-manager.io/cluster-issuer: letsencrypt-prod
      # nginx.ingress.kubernetes.io/ssl-redirect: "true"
      # nginx.ingress.kubernetes.io/backend-protocol: "GRPC"
      # kubernetes.io/ingress.class: nginx
      # kubernetes.io/tls-acme: "true"
    # -- OtelAgent Ingress Host names with their path details
    hosts:
      - host: otel-agent.domain.com
        paths:
          - path: /
            pathType: ImplementationSpecific
            port: 4317
    # -- OtelAgent Ingress TLS
    tls: []
    #  - secretName: chart-example-tls
    #    hosts:
    #      - otel-agent.domain.com

  # -- Configure resource requests and limits. Update according to your own use
  # case as these values might not be suitable for your workload.
  # ref: http://kubernetes.io/docs/user-guide/compute-resources/
  # @default -- See `values.yaml` for defaults
  resources:
    requests:
      cpu: 100m
      memory: 100Mi
    # limits:
    #   cpu: 1000m
    #   memory: 1Gi

  # -- OtelAgent priority class name
  priorityClassName: ""

  # -- OtelAgent node selector
  nodeSelector: {}

  # -- Toleration labels for OtelAgent pod assignment
  tolerations: []

  # -- Affinity settings for OtelAgent pod
  affinity: {}

  # -- Pod-level security configuration
  podSecurityContext: {}
    # fsGroup: 2000

  # -- Container security configuration
  securityContext: {}
    # capabilities:
    #   drop:
    #   - ALL
    # readOnlyRootFilesystem: true
    # runAsNonRoot: true
    # runAsUser: 1000

  # -- Configurations for OtelAgent
  # @default -- See `values.yaml` for defaults
  config:
    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: 0.0.0.0:4317
            max_recv_msg_size_mib: 4
          http:
            endpoint: 0.0.0.0:4318
    processors:
      # Batch processor config.
      # ref: https://github.com/open-telemetry/opentelemetry-collector/blob/main/processor/batchprocessor/README.md
      batch:
        send_batch_size: 10000
        timeout: 200ms
      # Memory Limiter processor.
      # If set to null, will be overridden with values based on k8s resource limits.
      # ref: https://github.com/open-telemetry/opentelemetry-collector/blob/main/processor/memorylimiterprocessor/README.md
      memory_limiter: null
    extensions:
      health_check:
        endpoint: 0.0.0.0:13133
      zpages:
        endpoint: localhost:55679
      pprof:
        endpoint: localhost:1777
    exporters: {}
    service:
      telemetry:
        metrics:
          address: 0.0.0.0:8888
      extensions: [health_check, zpages, pprof]
      pipelines:
        traces:
          receivers: [otlp]
          processors: [batch]
          exporters: []
        metrics:
          receivers: [otlp]
          processors: [batch]
          exporters: []
        metrics/internal:
          receivers: []
          processors: [batch]
          exporters: []
        logs:
          receivers: [otlp]
          processors: [batch]
          exporters: []

# Default values for OtelDeployment
otelDeployment:
  name: "otel-deployment"
  image:
    registry: docker.io
    repository: otel/opentelemetry-collector-contrib
    tag: 0.79.0
    pullPolicy: IfNotPresent

  # -- Image Registry Secret Names for OtelDeployment.
  # If global.imagePullSecrets is set as well, it will merged.
  imagePullSecrets: []
    # - "otelDeployment-pull-secret"

  # OpenTelemetry Collector executable
  command:
    # -- OtelDeployment command name
    name: /otelcol-contrib
    # -- OtelDeployment command extra arguments
    extraArgs: []

  configMap:
    # -- Specifies whether a configMap should be created (true by default)
    create: true

  # OtelDeployment service
  service:
    # -- Annotations to use by service associated to OtelDeployment
    annotations: {}
    # -- Service Type: LoadBalancer (allows external access) or NodePort (more secure, no extra cost)
    type: ClusterIP

  serviceAccount:
    # Specifies whether a service account should be created
    create: true
    # Annotations to add to the service account
    annotations: {}
    # The name of the service account to use.
    # If not set and create is true, a name is generated using the fullname template
    name:

  # -- OtelDeployment deployment annotation.
  annotations: {}
  # -- OtelDeployment pod(s) annotation.
  podAnnotations: {}
    # signoz.io/scrape: 'true'
    # signoz.io/port: '8888'
    # signoz.io/path: /metrics

  # -- Additional environments to set for OtelDeployment
  additionalEnvs: {}
    # env_key: env_value

  # -- Pod-level security configuration
  podSecurityContext: {}
    # fsGroup: 2000

  # -- Container security configuration
  securityContext: {}
    # capabilities:
    #   drop:
    #   - ALL
    # readOnlyRootFilesystem: true
    # runAsNonRoot: true
    # runAsUser: 1000

  # -- Minimum number of seconds for which a newly created Pod should be ready
  # without any of its containers crashing, for it to be considered available.
  minReadySeconds: 5

  # -- Number of seconds to wait for the OtelDeployment to progress before the
  # system reports back that the OtelDeployment has failed.
  progressDeadlineSeconds: 120

  # Configuration for ports
  ports:
    metrics:
      # -- Whether to enable service port for internal metrics
      enabled: false
      # -- Container port for internal metrics
      containerPort: 8888
      # -- Service port for internal metrics
      servicePort: 8888
      # -- Node port for internal metrics
      nodePort: ""
      # -- Protocol to use for internal metrics
      protocol: TCP
    zpages:
      # -- Whether to enable service port for ZPages
      enabled: false
      # -- Container port for Zpages
      containerPort: 55679
      # -- Service port for Zpages
      servicePort: 55679
      # -- Node port for Zpages
      nodePort: ""
      # -- Protocol to use for Zpages
      protocol: TCP
    health-check:
      # -- Whether to enable service port for health check
      enabled: true
      # -- Container port for health check
      containerPort: 13133
      # -- Service port for health check
      servicePort: 13133
      # -- Node port for health check
      nodePort: ""
      # -- Protocol to use for health check
      protocol: TCP
    pprof:
      # -- Whether to enable service port for pprof
      enabled: false
      # -- Container port for pprof
      containerPort: 1777
      # -- Service port for pprof
      servicePort: 1777
      # -- Node port for pprof
      nodePort: ""
      # -- Protocol to use for pprof
      protocol: TCP

  # -- Configure liveness probe.
  # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#define-a-liveness-command
  livenessProbe:
    enabled: true
    port: 13133
    path: /
    initialDelaySeconds: 10
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 6
    successThreshold: 1

  # -- Configure readiness probe.
  # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#define-readiness-probes
  readinessProbe:
    enabled: true
    port: 13133
    path: /
    initialDelaySeconds: 10
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 6
    successThreshold: 1

  # -- Custom liveness probe
  customLivenessProbe: {}

  # -- Custom readiness probe
  customReadinessProbe: {}

  ingress:
    # -- Enable ingress for OtelDeployment
    enabled: false
    # -- Ingress Class Name to be used to identify ingress controllers
    className: ""
    # -- Annotations to OtelDeployment Ingress
    annotations: {}
      # cert-manager.io/cluster-issuer: letsencrypt-prod
      # nginx.ingress.kubernetes.io/ssl-redirect: "true"
      # nginx.ingress.kubernetes.io/backend-protocol: "GRPC"
      # kubernetes.io/ingress.class: nginx
      # kubernetes.io/tls-acme: "true"
    # -- OtelDeployment Ingress Host names with their path details
    hosts:
      - host: otel-deployment.domain.com
        paths:
          - path: /
            pathType: ImplementationSpecific
            port: 13133
    # -- OtelDeployment Ingress TLS
    tls: []
    #  - secretName: chart-example-tls
    #    hosts:
    #      - otel-deployment.domain.com

  # -- Configure resource requests and limits. Update according to your own use
  # case as these values might not be suitable for your workload.
  # ref: http://kubernetes.io/docs/user-guide/compute-resources/
  # @default -- See `values.yaml` for defaults
  resources:
    requests:
      cpu: 100m
      memory: 100Mi
    # limits:
    #   cpu: 1000m
    #   memory: 1Gi

  # -- OtelDeployment priority class name
  priorityClassName: ""

  # -- OtelDeployment node selector
  nodeSelector: {}

  # -- Toleration labels for OtelDeployment pod assignment
  tolerations: []

  # -- Affinity settings for OtelDeployment pod
  affinity: {}

  # OtelDeployment RBAC config
  clusterRole:
    # -- Specifies whether a clusterRole should be created
    create: true
    # -- Annotations to add to the clusterRole
    annotations: {}
    # -- The name of the clusterRole to use.
    # If not set and create is true, a name is generated using the fullname template
    name: ""
    # -- A set of rules as documented here.
    # ref: https://kubernetes.io/docs/reference/access-authn-authz/rbac/
    # @default -- See `values.yaml` for defaults
    rules:
      - apiGroups: [""]
        resources:
          - events
          - namespaces
          - namespaces/status
          - nodes
          - nodes/spec
          - pods
          - pods/status
          - replicationcontrollers
          - replicationcontrollers/status
          - resourcequotas
          - services
        verbs: ["get", "list", "watch"]
      - apiGroups: ["apps"]
        resources: ["daemonsets", "deployments", "replicasets", "statefulsets"]
        verbs: ["get", "list", "watch"]
      - apiGroups: ["extensions"]
        resources: ["daemonsets", "deployments", "replicasets"]
        verbs: ["get", "list", "watch"]
      - apiGroups: ["batch"]
        resources: ["jobs", "cronjobs"]
        verbs: ["get", "list", "watch"]
      - apiGroups: ["autoscaling"]
        resources: ["horizontalpodautoscalers"]
        verbs: ["get", "list", "watch"]

    # OtelDeployment clusterRoleBinding
    clusterRoleBinding:
      # -- Annotations to add to the clusterRoleBinding
      annotations: {}
      # -- The name of the clusterRoleBinding to use.
      # If not set and create is true, a name is generated using the fullname template
      name: ""

  # -- Configurations for OtelDeployment
  # @default -- See `values.yaml` for defaults
  config:
    receivers: {}
    processors:
      # Batch processor config.
      # ref: https://github.com/open-telemetry/opentelemetry-collector/blob/main/processor/batchprocessor/README.md
      batch:
        send_batch_size: 10000
        timeout: 1s
      # Memory Limiter processor.
      # If set to null, will be overridden with values based on k8s resource limits.
      # ref: https://github.com/open-telemetry/opentelemetry-collector/blob/main/processor/memorylimiterprocessor/README.md
      memory_limiter: null
    extensions:
      health_check:
        endpoint: 0.0.0.0:13133
      zpages:
        endpoint: localhost:55679
      pprof:
        endpoint: localhost:1777
    exporters: {}
    service:
      telemetry:
        metrics:
          address: 0.0.0.0:8888
      extensions: [health_check, zpages, pprof]
      pipelines:
        metrics/internal:
          receivers: []
          processors: [batch]
          exporters: []
